---
title: "Independent Events"
subtitle: "Mathematical Statistics"
author:
  - name: "Samir Orujov, PhD"
    affiliations:
      - name: "ADA University, School of Business"
      - name: "Information Communication Technologies Agency, Statistics Unit"
date: today
format: 
  revealjs:
    theme: default
    logo: ADA.png
    transition: slide
    slide-number: true
    chalkboard: true
    controls: true
    navigation-mode: vertical
    width: 1280
    height: 720
    footer: "Mathematical Statistics - Independent Events"
    incremental: false
    highlight-style: tango
    code-fold: true
    menu: true
    progress: true
    history: true
---

## Overview {.center}

:::: {.columns}

::: {.column width="50%"}
### Today's Journey
- 📐 Independent Events Definition
- 🔗 Properties of Independence
- 🎲 Multiple Event Independence
- 🌍 Real-world Applications
:::

::: {.column width="50%"}
### Learning Objectives
- ✅ Understand independence concept
- 🧮 Apply independence formulas
- ⚖️ Distinguish independence from mutual exclusivity
- 🎯 Solve complex probability problems
:::

::::

---

## Think-Pair-Share: Card Intuition {.center}

::: {.fragment .fade-in}
**🃏 Scenario:** Drawing a card from a standard deck...

*Think (30 seconds):* Does knowing a card is a spade affect the probability it's an ace?
:::

::: {.fragment .fade-in}
**👥 Pair (1 minute):** Discuss with your neighbor
:::

::: {.fragment .fade-in}
**🗣️ Share:** Let's hear your reasoning!
:::

---

## Definition of Independent Events {.center}

::: {.callout-important}
## Definition #1

Two events $E$ and $F$ are said to be **independent** if:

$$P(EF) = P(E)P(F)$$

holds.
:::

::: {.fragment .fade-in}
Two events $E$ and $F$ that are not independent are said to be **dependent**.
:::

---

## Intuitive Understanding

::: {.fragment .fade-in}
**Key Insight:**

$E$ is independent of $F$ if knowledge that $F$ has occurred does **not change** the probability that $E$ occurs.
:::

::: {.fragment .fade-in}
**Symmetry Property:**

Whenever $E$ is independent of $F$, then $F$ is also independent of $E$.
:::

::: {.fragment .fade-in}
**🤔 Discussion Moment:** Why does this symmetry make intuitive sense?
:::

---

## Example 1: Playing Cards {.center}

**Setup:** A card is selected at random from an ordinary deck of 52 playing cards.

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
**Events:**

- $E$: The selected card is an ace
- $F$: The selected card is a spade
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
**Question:** Are $E$ and $F$ independent?
:::

::: {.fragment .fade-in}
**🎯 Quick Poll:** What do you think?

- A) Yes, independent
- B) No, dependent
- C) Not enough information
:::
:::
:::


---

## Example 1: Solution {.center .smaller}

::: {.fragment .fade-in}
**Calculate each probability:**

- $P(EF) = P(\text{ace of spades}) = \frac{1}{52}$
- $P(E) = P(\text{ace}) = \frac{4}{52}$
- $P(F) = P(\text{spade}) = \frac{13}{52}$
:::

::: {.fragment .fade-in}
**Check independence:**

$$P(E)P(F) = \frac{4}{52} \times \frac{13}{52} = \frac{52}{52^2} = \frac{1}{52} = P(EF)$$
:::

::: {.fragment .fade-in}
::: {.callout-tip}
## Conclusion
$E$ and $F$ are **independent**! ✓
:::
:::

---

## Example 2: Two Coins {.center}

**Experiment:** Two coins are flipped, and all 4 outcomes are assumed equally likely.

::: {.fragment .fade-in}
**Sample Space:** $S = \{HH, HT, TH, TT\}$

**Events:**

- $E$: First coin lands on heads
- $F$: Second coin lands on tails
:::

::: {.fragment .fade-in}
**🧠 Think-Write-Pair:** Take 1 minute to determine if $E$ and $F$ are independent.
:::

---

## Example 2: Solution {.center}

::: columns
::: {.column width="55%"}
::: {.fragment .fade-in}
**Identify outcomes:**

- $E = \{HH, HT\}$, so $P(E) = \frac{2}{4} = \frac{1}{2}$
- $F = \{HT, TT\}$, so $P(F) = \frac{2}{4} = \frac{1}{2}$
- $EF = \{HT\}$, so $P(EF) = \frac{1}{4}$
:::
:::

::: {.column width="45%"}
::: {.fragment .fade-in}
**Verify independence:**

$$P(E)P(F) = \frac{1}{2} \times \frac{1}{2} = \frac{1}{4} = P(EF)$$
:::

::: {.fragment .fade-in}
::: {.callout-tip icon=false}
## Result
$E$ and $F$ are **independent**! ✓
:::
:::
:::
:::

---

## Example 3: Two Dice - Part 1 {.center}

**Experiment:** Toss 2 fair dice.

::: {.fragment .fade-in}
**Events:**

- $E_1$: Sum of the dice equals 6
- $F$: First die equals 4
:::

::: {.fragment .fade-in}
**Question:** Are $E_1$ and $F$ independent?
:::

::: {.fragment .fade-in}
**⏱️ Group Activity:** Work in pairs for 2 minutes
:::

---

## Example 3: Solution - Part 1 {.center}

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
**Calculate probabilities:**

- $P(F) = \frac{6}{36} = \frac{1}{6}$ (first die = 4)
- $P(E_1) = \frac{5}{36}$ (sums to 6: (1,5), (2,4), (3,3), (4,2), (5,1))
- $P(E_1F) = \frac{1}{36}$ (only (4,2))
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
::: {style="font-size: 35px"}
**Check independence:**
$$P(E_1)P(F) = \frac{5}{36} \times \frac{1}{6} = \frac{5}{216} \neq \frac{1}{36} = P(E_1F)$$
:::
:::
:::

::: {.fragment .fade-in style="margin-top: -2rem"}
::: {.callout-warning}
## Conclusion
$E_1$ and $F$ are **not independent**! ✗
:::
:::
:::

---

## Question #1: Two Dice - Part 2 {.center}

**New Event:**

- $E_2$: Sum of the dice equals 7

::: {.fragment .fade-in}
**Question:** Is $E_2$ independent of $F$?
:::

::: {.fragment .fade-in}
**🎯 Your Challenge:** Verify independence
:::

::: {.fragment .fade-in}
**⏱️ Time:** 2 minutes individually
:::

---

## Question #1: Solution {.center}

::: {.fragment .fade-in}
**Calculate probabilities:**

- $P(E_2) = \frac{6}{36} = \frac{1}{6}$ (sums to 7: six outcomes)
- $P(F) = \frac{1}{6}$ (first die = 4)
- $P(E_2F) = \frac{1}{36}$ (only (4,3))
:::

::: {.fragment .fade-in style="margin-top: -2rem"}
**Check independence:**

::: {style="margin-top: -4rem"}
$$P(E_2)P(F) = \frac{1}{6} \times \frac{1}{6} = \frac{1}{36} = P(E_2F)$$
:::
:::

::: {.fragment .fade-in}
::: {.callout-tip}
## Conclusion
$E_2$ and $F$ are **independent**! ✓
:::
:::

---

## Proposition #1: Complement Property {.center}

::: {.callout-note}
## Proposition #1

If $E$ and $F$ are independent, then so are $E$ and $F^c$.
:::

::: {.fragment .fade-in}
**🤔 Discussion:** Why is this property useful in practice?
:::

::: {.fragment .fade-in}
**Hint:** Often easier to compute probability of complement!
:::

---

## Think-Pair-Share: Three Events {.center}

::: {.fragment .fade-in}
**🧩 Scenario:**

Suppose $E$ is independent of $F$ and $E$ is also independent of $G$.
:::

::: {.fragment .fade-in}
**Question #2:** Is $E$ necessarily independent of $FG$?

**🤔 Think (1 minute):** Form a hypothesis

**👥 Pair (2 minutes):** Test your hypothesis with examples
:::

---

## Question #2: Counter Example {.center}


**Example 4:**

Two fair dice are thrown.

::: columns
::: {.column width="50%"}
**Events:**

- $E$: Sum of the dice is 7
- $F$: First die equals 4
- $G$: Second die equals 3
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
**🎯 Group Challenge:** 

1. Verify $E$ is independent of $F$
2. Verify $E$ is independent of $G$
3. Check if $E$ is independent of $FG$
:::
:::
:::


---

## Example 4: Solution {.center}


::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
**Verifying independence:**

- $P(E) = \frac{1}{6}$, $P(F) = \frac{1}{6}$, $P(G) = \frac{1}{6}$
- $P(EF) = \frac{1}{36} = P(E)P(F)$ ✓ Independent
- $P(EG) = \frac{1}{36} = P(E)P(G)$ ✓ Independent
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
**But what about $FG$?**

- $FG = \{(4,3)\}$, so $P(FG) = \frac{1}{36}$
- $EFG = \{(4,3)\}$, so $P(EFG) = \frac{1}{36}$
- $P(E)P(FG) = \frac{1}{6} \times \frac{1}{36} = \frac{1}{216} \neq \frac{1}{36}$ ✗
:::
:::
:::

::: {.fragment .fade-in style="margin-top: -3rem"}
::: {.callout-warning}
## Answer
NO! Pairwise independence ≠ independence of intersection
:::
:::

---

## Definition #2: Three Independent Events {.center}

::: {.callout-important}
## Definition #2

The events $E$, $F$, and $G$ are said to be **independent** if:

$$P(EFG) = P(E)P(F)P(G)$$
$$P(EF) = P(E)P(F)$$
$$P(EG) = P(E)P(G)$$
$$P(FG) = P(F)P(G)$$
:::

::: {.fragment .fade-in}
**💡 Key Point:** ALL four conditions must hold!
:::

---

## Remark #1: Event Combinations {.center}

::: {.fragment .fade-in}
**Important Property:**

If $E$, $F$, and $G$ are independent, then $E$ will be independent of **any event formed** from $F$ and $G$.
:::

::: {.fragment .fade-in}
**Examples of events formed from $F$ and $G$:**

- $F \cup G$
- $F^c \cap G$
- $F \cup G^c$
- etc.
:::

---

## Definition #3: n Independent Events {.center}

::: {.callout-important}
## Definition #3

The events $E_1, E_2, \ldots, E_n$ are said to be **independent** if for every subset $E_1', E_2', \ldots, E_r'$, $r \leq n$, of these events:

$$P(E_1'E_2' \cdots E_r') = P(E_1')P(E_2') \cdots P(E_r')$$
:::

::: {.fragment .fade-in}
**Infinite sets:** We define an infinite set of events to be independent if every **finite subset** is independent.
:::

---

## Example 5: Independent Trials {.center}

**Setup:** An infinite sequence of independent trials is performed. Each trial results in:

- Success with probability $p$
- Failure with probability $1-p$

::: {.fragment .fade-in}
**What is the probability that:**

1. At least 1 success occurs in the first $n$ trials?
:::

::: {.fragment .fade-in}
**🎯 Student Activity:** Work this out before we reveal the answer!

**⏱️ Time:** 2 minutes
:::

---

## Example 5: Part (a) Solution {.center}

::: {.fragment .fade-in}
**Question:** P(at least 1 success in first $n$ trials)?

**Strategy:** Use complement!
:::

::: {.fragment .fade-in}
**Solution:**

Let $E_i$ = success on trial $i$

$$P(\text{at least 1 success}) = 1 - P(\text{all failures})$$
$$= 1 - P(E_1^c E_2^c \cdots E_n^c)$$
$$= 1 - P(E_1^c)P(E_2^c) \cdots P(E_n^c)$$
$$= 1 - (1-p)^n$$
:::

---

## Example 5: More Questions {.center}

**What is the probability that:**

::: {.fragment .fade-in}
2. Exactly $k$ successes occur in the first $n$ trials?
:::

::: {.fragment .fade-in}
3. All trials result in successes?
:::

::: {.fragment .fade-in}
**👥 Pair Work:** Take 3 minutes to solve parts (b) and (c) with a partner
:::

---

## Example 5: Part (b) Solution {.center}

::: {.fragment .fade-in}
**Question:** P(exactly $k$ successes in first $n$ trials)?

**Key Insight:** This is a binomial distribution!
:::

::: {.fragment .fade-in}
**Solution:**

- Choose which $k$ trials are successes: $\binom{n}{k}$ ways
- Each specific sequence has probability $p^k(1-p)^{n-k}$

$$P(\text{exactly } k \text{ successes}) = \binom{n}{k}p^k(1-p)^{n-k}$$
:::

---

## Example 5: Part (c) Solution {.center}

::: {.fragment .fade-in}
**Question:** P(all trials result in successes)?

**This is asking:** P(infinite sequence of successes)
:::

::: {.fragment .fade-in}
**Solution:**

For all $n$ trials to be successes:
$$P(\text{first } n \text{ all successes}) = p^n$$

For **infinite** trials:
$$P(\text{all infinite trials successes}) = \lim_{n \to \infty} p^n = 0$$

(assuming $0 < p < 1$)
:::

---

## Example 6: Dice Competition {.center}

**Setup:** Independent trials of rolling a pair of fair dice are performed.

::: {.fragment .fade-in}
**Question:** What is the probability that an outcome of 5 appears **before** an outcome of 7?

(The outcome of a roll is the sum of the dice)
:::

::: {.fragment .fade-in}
**🧠 Group Discussion:** What strategy should we use?

**⏱️ Time:** 2 minutes to brainstorm
:::

---

## Example 6: Solution Approach {.center}

::: {.fragment .fade-in}
**First, find basic probabilities:**

- $P(\text{sum} = 5) = \frac{4}{36} = \frac{1}{9}$ 
  - Outcomes: (1,4), (2,3), (3,2), (4,1)
- $P(\text{sum} = 7) = \frac{6}{36} = \frac{1}{6}$
- $P(\text{neither 5 nor 7}) = 1 - \frac{1}{9} - \frac{1}{6} = \frac{13}{18}$
:::

::: {.fragment .fade-in}
**Strategy:** Use a general formula...
:::

---

## Formula #1: First Occurrence {.center}

::: {.callout-note}
## Formula #1

If $E$ and $F$ are **mutually exclusive** events of an experiment, then when independent trials of the experiment are performed, the event $E$ will occur before $F$ with probability:

$$P(E \text{ before } F) = \frac{P(E)}{P(E) + P(F)}$$
:::

---

## Example 6: Final Solution {.center}

::: {.fragment .fade-in}
**Apply Formula #1:**

$$P(5 \text{ before } 7) = \frac{P(\text{sum} = 5)}{P(\text{sum} = 5) + P(\text{sum} = 7)}$$
$$= \frac{\frac{1}{9}}{\frac{1}{9} + \frac{1}{6}} = \frac{\frac{1}{9}}{\frac{5}{18}} = \frac{1}{9} \times \frac{18}{5} = \frac{2}{5}$$
:::

::: {.fragment .fade-in}
::: {.callout-tip}
## Answer
The probability is $\frac{2}{5}$ or 0.4
:::
:::

---

## Think-Pair-Share: Coupon Problem {.center}

::: {.fragment .fade-in}
**Example 7 (HW):**

Suppose there are $n$ types of coupons. Each new coupon collected is, independent of previous selections, a type $i$ coupon with probability $p_i$, where $\sum_{i=1}^{n} p_i = 1$.
:::

::: {.fragment .fade-in}
Suppose $k$ coupons are collected. Let $A_i$ = event that there is at least one type $i$ coupon among those collected.

**For $i \neq j$, find:**

a) $P(A_i)$
b) $P(A_i \cup A_j)$
c) $P(A_i | A_j)$
:::

---

## Example 7: Hints for Solutions

::: {.fragment .fade-in}
::: {.callout-tip collapse="true"}
## Part (a) - Hint

Use complement! What's the probability of NOT getting any type $i$ coupon?

**Answer:** $P(A_i) = 1 - (1-p_i)^k$
:::
:::

::: {.fragment .fade-in}
::: {.callout-tip collapse="true"}
## Part (b) - Hint

Use inclusion-exclusion principle: $P(A \cup B) = P(A) + P(B) - P(AB)$

**Answer:** $P(A_i \cup A_j) = 1 - (1-p_i)^k - (1-p_j)^k + (1-p_i-p_j)^k$
:::
:::

::: {.fragment .fade-in}
::: {.callout-tip collapse="true"}
## Part (c) - Hint

Use conditional probability formula and think about what changes given $A_j$.
:::
:::

---

## Example 8: The Problem of the Points {.center}

::: {.callout-note}
## Classic Problem

Independent trials resulting in a success with probability $p$ and a failure with probability $1-p$ are performed.

**Question:** What is the probability that $n$ successes occur **before** $m$ failures?
:::

::: {.fragment .fade-in}
**🏆 Challenge Problem:** Work on this in study groups!
:::

---

## Example 8: Solution Strategy {.center}

::: {.fragment .fade-in}
**Key Insight:** The game ends after at most $n + m - 1$ trials.
:::

::: {.fragment .fade-in}
**Better approach:**

Consider all $n+m-1$ trials. We win if we get at least $n$ successes.

$$P = \sum_{k=n}^{n+m-1} \binom{n+m-1}{k} p^k (1-p)^{n+m-1-k}$$
:::

::: {.fragment .fade-in}
**Alternative:** Think of it as needing $n$ successes in at most $n+m-1$ trials.

This is equivalent to NOT getting $m$ failures first!
:::

---

## Example 9: Service Protocol (HW) {.center}

**Tennis/Volleyball Serving Rules:**

::: {.fragment .fade-in}
- Rally with A serving: A wins with probability $p_A$, B wins with $q_A = 1-p_A$
- Rally with B serving: A wins with probability $p_B$, B wins with $q_B = 1-p_B$
- Player A is initial server
:::

::: {.fragment .fade-in}
**Two protocols under consideration:**

1. **"Winner serves"** - winner of rally serves next
2. **"Alternating serve"** - players alternate serving
:::

::: {.fragment .fade-in}
**Question:** If you were player A, which protocol would you prefer?
:::

---

## Example 9: Analysis Hints {.center}

::: {.fragment .fade-in}
::: {.callout-tip collapse="true"}
## Winner Serves Protocol

Let $P_A$ = probability A eventually wins game starting as server

Think about what happens after first rally...

Set up: $P_A = p_A P_A + q_A P_B$ where $P_B$ satisfies $P_B = p_B P_A + q_B P_B$
:::
:::

::: {.fragment .fade-in}
::: {.callout-tip collapse="true"}
## Alternating Serves Protocol

More complex! Need to track:

- Who is serving
- Current score
- Pattern of serves
:::
:::

---

## Example 10: The Gambler's Ruin Problem {.center}

::: {.callout-note}
## Classic Problem

Two gamblers, A and B, bet on outcomes of successive coin flips.

- Heads: A collects 1 unit from B
- Tails: A pays 1 unit to B
- Continue until someone runs out of money
:::

::: {.fragment .fade-in}
**Question:** If A starts with $i$ units and B starts with $N-i$ units, what is the probability that A ends up with all the money?

(Each flip results in heads with probability $p$)
:::

---

## Example 10: Solution Setup {.center}

::: {.fragment .fade-in}
**Let $P_i$ = probability A wins starting with $i$ units**

**Boundary conditions:**

- $P_0 = 0$ (A already lost)
- $P_N = 1$ (A already won)
:::

::: {.fragment .fade-in}
**Recursive relation:**

After first flip, A has either $i+1$ or $i-1$ units:

$$P_i = p \cdot P_{i+1} + (1-p) \cdot P_{i-1}$$
:::

---

## Example 10: General Solution {.center}

::: {.fragment .fade-in}
::: {.callout-tip}
## Case 1: Fair coin ($p = \frac{1}{2}$)

$$P_i = \frac{i}{N}$$
:::
:::

::: {.fragment .fade-in}
::: {.callout-tip}
## Case 2: Biased coin ($p \neq \frac{1}{2}$)

$$P_i = \frac{1 - \left(\frac{1-p}{p}\right)^i}{1 - \left(\frac{1-p}{p}\right)^N}$$
:::
:::

::: {.fragment .fade-in}
**🎲 Insight:** If the game is unfair ($p \neq \frac{1}{2}$), the probability depends strongly on the ratio of odds!
:::

---

## Group Activity: Drug Test Analysis {.center}

**Example 11 (HW):**

::: {.fragment .fade-in}
Two new drugs for treating a disease have cure rates $P_1$ and $P_2$ (unknown).

**Testing procedure:**

- Treat pairs of patients sequentially (one gets drug 1, other gets drug 2)
- Stop when cumulative cures from one drug exceeds the other by a fixed amount $d$
:::

::: {.fragment .fade-in}
**Question:** For given $P_1$ and $P_2$ where $P_1 > P_2$, what is the probability the test incorrectly asserts $P_2 > P_1$?
:::

---

## Example 11: Problem Structure {.center}

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
**This is related to:**

- Random walks
- Sequential analysis
- Gambler's ruin problem!
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
**Key differences:**

- Four possible outcomes per pair: (cure, cure), (cure, no cure), (no cure, cure), (no cure, no cure)
- Only the **difference** in cure counts matters
:::
:::
:::

::: {.fragment .fade-in}
**🔬 Research Project:** Develop the full solution as homework!
:::

---

## Interactive Review: Quick Quiz {.center}

<style>
.quiz-button {
  padding: 12px 25px;
  margin: 8px;
  font-size: 20px;
  border: 2px solid #333;
  border-radius: 10px;
  cursor: pointer;
  background-color: #f8f9fa;
  transition: all 0.3s ease;
  font-weight: 500;
}

.quiz-button:hover {
  background-color: #e9ecef;
  transform: scale(1.05);
  box-shadow: 0 4px 8px rgba(0,0,0,0.2);
}

.quiz-button.correct {
  background-color: #28a745;
  color: white;
  border-color: #28a745;
}

.quiz-button.incorrect {
  background-color: #dc3545;
  color: white;
  border-color: #dc3545;
}

.quiz-button:disabled {
  cursor: not-allowed;
  opacity: 0.7;
}

.feedback {
  margin-top: 20px;
  padding: 20px;
  border-radius: 10px;
  font-size: 22px;
  font-weight: 600;
  display: none;
  animation: fadeIn 0.5s;
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}

.feedback.correct {
  background-color: #d4edda;
  color: #155724;
  border: 3px solid #28a745;
  display: block;
}

.feedback.incorrect {
  background-color: #f8d7da;
  color: #721c24;
  border: 3px solid #dc3545;
  display: block;
}

.quiz-question {
  margin: 40px 0;
  padding: 20px;
  background-color: #f8f9fa;
  border-radius: 10px;
}

.quiz-question p {
  font-size: 24px;
  margin-bottom: 20px;
}
</style>

<div class="quiz-question">
<p><strong>Q1:</strong> If $E$ and $F$ are independent and $P(E) = 0.3$, $P(F) = 0.5$, what is $P(EF)$?</p>

<button class="quiz-button" onclick="checkAnswer(this, 'q1', 'A')">A) 0.15</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q1', 'B')">B) 0.30</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q1', 'C')">C) 0.50</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q1', 'D')">D) 0.80</button>

<div id="feedback-q1" class="feedback"></div>
</div>

---

## Interactive Review: Quiz (cont.) {.center .smaller}

<div class="quiz-question">
<p><strong>Q2:</strong> If events are mutually exclusive, can they be independent?</p>

<button class="quiz-button" onclick="checkAnswer(this, 'q2', 'A')">A) Yes, always</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q2', 'B')">B) No, never (if both have positive probability)</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q2', 'C')">C) Sometimes</button>

<div id="feedback-q2" class="feedback"></div>
</div>

<div class="quiz-question">
<p><strong>Q3:</strong> How many conditions must be checked to verify three events are independent?</p>

<button class="quiz-button" onclick="checkAnswer(this, 'q3', 'A')">A) 1</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q3', 'B')">B) 3</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q3', 'C')">C) 4</button>
<button class="quiz-button" onclick="checkAnswer(this, 'q3', 'D')">D) 7</button>

<div id="feedback-q3" class="feedback"></div>
</div>

<script>
const answers = {
  q1: { 
    correct: 'A', 
    explanation: 'For independent events: P(EF) = P(E)P(F) = 0.3 × 0.5 = 0.15' 
  },
  q2: { 
    correct: 'B', 
    explanation: 'Mutually exclusive events with positive probability cannot be independent because P(EF) = 0 but P(E)P(F) > 0' 
  },
  q3: { 
    correct: 'C', 
    explanation: 'Four conditions must be checked: P(EFG), P(EF), P(EG), and P(FG)' 
  }
};

function checkAnswer(button, questionId, answer) {
  const buttons = button.parentElement.querySelectorAll('.quiz-button');
  const feedback = document.getElementById('feedback-' + questionId);
  const correctAnswer = answers[questionId].correct;

  buttons.forEach(btn => btn.disabled = true);

  if (answer === correctAnswer) {
    button.classList.add('correct');
    feedback.innerHTML = '✅ <strong>Correct!</strong> ' + answers[questionId].explanation;
    feedback.classList.remove('incorrect');
    feedback.classList.add('correct');
  } else {
    button.classList.add('incorrect');
    buttons.forEach(btn => {
      if (btn.textContent.trim().startsWith(correctAnswer + ')')) {
        btn.classList.add('correct');
      }
    });
    feedback.innerHTML = '❌ <strong>Incorrect.</strong> The correct answer is <strong>' + correctAnswer + '</strong>. ' + answers[questionId].explanation;
    feedback.classList.remove('correct');
    feedback.classList.add('incorrect');
  }
}
</script>

---

## Key Concepts Summary {.center}

:::: {.columns}

::: {.column width="50%"}
**🎯 Main Takeaways:**

- Independence: $P(EF) = P(E)P(F)$
- Independence ≠ Mutual Exclusivity
- Pairwise independence ≠ Full independence
- Complement property is powerful
:::

::: {.column width="50%"}
**🔗 Connections:**

- Conditional probability: $P(E|F) = P(E)$ when independent
- Multiplication rule simplifies for independent events
- Bernoulli trials are independent
:::

::::

---

## Real-World Applications {.center}

::: {.fragment .fade-in}
**Where independence matters:**

- 🏭 Quality control: defects in manufacturing
- 📈 Finance: returns on different stocks (often NOT independent!)
- 💊 Medicine: treatment outcomes for different patients
- ⚽ Sports: game outcomes (if truly independent)
- 🔧 Reliability engineering: component failures
:::

::: {.fragment .fade-in}
::: {.callout-warning}
⚠️ **Warning:** Always verify independence assumptions!
:::
:::

---

## Common Pitfalls {.center .large}

::: {style="font-size: 50px"}

::: columns
::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-warning}
## ❌ Mistake #1
Assuming independence without verification

**Example:** Card draws without replacement are NOT independent
:::
:::
:::

::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-warning}
## ❌ Mistake #2
Confusing independence with mutual exclusivity

**Key:** Mutually exclusive events (with positive probability) cannot be independent!
:::
:::
:::

::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-warning}
## ❌ Mistake #3
Assuming pairwise independence implies full independence

**Remember:** Need to check ALL subset products!
:::
:::
:::
:::
:::

---

## Problem-Solving Strategies {.center}

::: {style="font-size: 40px"}

::: columns
::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-tip}
## Strategy #1: "At least one"
Use complement: $P(\text{at least one}) \\ = 1 - P(\text{none})$
:::
:::
:::

::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-tip}
## Strategy #2: Independent events
Probabilities multiply: $$P(E_1 E_2 \cdots E_n)  \\ = P(E_1)P(E_2) \cdots P(E_n)$$
:::
:::
:::

::: {.column width="33%"}
::: {.fragment .fade-in}
::: {.callout-tip}
## Strategy #3: "Before" problems
Use Formula #1 or set up recursive equations
:::
:::
:::
:::
:::

---

## Homework Problems {.center}

:::: {.columns}

::: {.column width="50%"}
**📚 Required:**

1. Example 7 (Coupon Problem) - all parts
2. Example 9 (Service Protocol) - full analysis
3. Example 11 (Drug Test) - derive probability formula
:::

::: {.column width="50%"}
**🏆 Optional Challenges:**

4. Prove Formula #1 (first occurrence)
5. Derive full solution to Example 10 (Gambler's Ruin)
6. Create your own independence problem
:::

::::

---

## Next Class Preview {.center}

::: {.fragment .fade-in}
**🔜 Coming Up:**

::: {style="margin-top: -2rem"}
- Bayes' Theorem
- Total Probability Law
- Advanced conditional probability
- Applications to real-world inference problems
:::
:::

::: {.fragment .fade-in}
**📚 Preparation:**

::: {style="margin-top: -2rem"}
- Review conditional probability
- Think about how independence relates to conditioning
- Read textbook sections on Bayes' Theorem
:::
:::

---

## Final Reflection {.center}

::: {.fragment .fade-in}
**🤔 Think About:**

1. How does independence simplify probability calculations?
2. When is it reasonable to assume independence in real life?
3. What's the relationship between independence and information?
:::

::: {.fragment .fade-in}
**💬 Discussion Question:**

"Independence means events don't influence each other" - Is this always true? Can you think of situations where this intuition might mislead you?
:::

::: {.fragment .fade-in}
**✨ Remember:** Independence is one of the most powerful concepts in probability theory!
:::

---

## Questions? {.center}

::: {.r-fit-text style="font-size: 60px;"}

**Thank you!**

:::

**Office Hours:** Get appointment by email

**Contact:** sorujov@ada.edu.az

